{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57a2ec31",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6e88bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5fec9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_classes = 6\n",
    "batch_size = 32\n",
    "train_on = 'Karolinska'\n",
    "\n",
    "magnification = 'heterogeneous' # ['10', '20', '40', 'heterogeneous', 'homogeneous']\n",
    "fold = 'fold1' \n",
    "iterate = 1\n",
    "\n",
    "# model_name = '_2GCN_1GIN_2GCN_concat_deeppool_2linear_layernorm'\n",
    "# model_name = '_MS_RGCN_4relu'\n",
    "model_name = '_MS_RGCN'\n",
    "\n",
    "if train_on == 'Karolinska':\n",
    "    model_path = 'models/{}/model_mag_{}_{}.pth'.format(fold, magnification + model_name, iterate)\n",
    "    data_path = f'{train_on}_data/'\n",
    "\n",
    "print(model_path)\n",
    "# path_VPC = '../feature_extractor_6class/VPC_embeddings/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f70611b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60867769",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import for RGATConv\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch.nn import Parameter, ReLU, Sequential\n",
    "from torch_scatter import scatter_add\n",
    "from torch_sparse import SparseTensor\n",
    "\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.nn.dense.linear import Linear\n",
    "from torch_geometric.nn.inits import glorot, ones, zeros\n",
    "from torch_geometric.typing import Adj, OptTensor, Size\n",
    "from torch_geometric.utils import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f23dc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import dgl\n",
    "# from dgl.data import DGLDataset\n",
    "from torch_geometric.data import Dataset\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import ModuleDict\n",
    "from torch_geometric.nn import GCNConv, RGCNConv, global_mean_pool, to_hetero, GATConv, SAGPooling, BatchNorm, LayerNorm, AGNNConv, ResGatedGraphConv, SGConv, GINConv #, InstanceNorm, GraphNorm, PairNorm\n",
    "import os\n",
    "import networkx as nx # graph visualization\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from sklearn.metrics import roc_auc_score, balanced_accuracy_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import time\n",
    "# from pyg_class.RGAT_Conv import RGATConv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3ff60b-db83-4df0-960c-c02753e09026",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f987d5f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a function to move tensors from the Double to Float\n",
    "def dict_to_float(orig):\n",
    "    new = {}\n",
    "    for k,v in orig.items():\n",
    "        new[k] = v.float()\n",
    "    return new\n",
    "\n",
    "def get_edge_index_type(data):\n",
    "    edge_index = torch.empty((2,0), dtype=torch.long).cuda()\n",
    "    edge_type = torch.empty((0), dtype=torch.long).cuda()\n",
    "    for i, t in enumerate(data.edge_types):\n",
    "        edge_index = torch.cat((edge_index, data.edge_index_dict[t]), 1)\n",
    "        edge_type = torch.cat((edge_type, torch.ones(data.edge_index_dict[t].shape[1]).cuda()*i))\n",
    "    return edge_index, edge_type\n",
    "\n",
    "def quadratic_weighted_kappa(y_hat, y):\n",
    "    return cohen_kappa_score(y_hat, y, weights=\"quadratic\")\n",
    "\n",
    "class SaveBestModel:\n",
    "    \"\"\"\n",
    "    Class to save the best model while training. If the current epoch's \n",
    "    validation loss is less than the previous least less, then save the\n",
    "    model state.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.best_acc = 0\n",
    "        \n",
    "    def __call__(\n",
    "        self, current_acc, \n",
    "        epoch, model, optimizer\n",
    "    ):\n",
    "        if current_acc > self.best_acc:\n",
    "            self.best_acc = current_acc\n",
    "            print(f\"\\nBest validation AUC: {self.best_acc}\")\n",
    "            print(f\"\\nSaving best model for epoch: {epoch+1}\\n\")\n",
    "            torch.save({\n",
    "                'epoch': epoch+1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_acc': current_acc\n",
    "                }, model_path)\n",
    "            \n",
    "save_model = SaveBestModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bc68d7",
   "metadata": {},
   "source": [
    "# PYG Utils by Roozbeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6c33b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GlobalAttentionPooling(torch.nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.att = torch.nn.MultiheadAttention(embed_dim, num_heads, dropout, batch_first=True)\n",
    "        \n",
    "    def forward(self, x, batch):\n",
    "        batch_size = batch[-1].detach() + 1\n",
    "        embed_dim = x.shape[-1]\n",
    "        output = torch.zeros((batch_size, embed_dim)).to(x.get_device())\n",
    "        for b in range(batch_size):\n",
    "            x_batch = x[batch == b].unsqueeze(0)\n",
    "            attn_output, _ = self.att(x_batch, x_batch, x_batch)\n",
    "            output[b] = torch.mean(attn_output[0], dim=0)\n",
    "            \n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba726f0",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a46dd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VPCDataset(Dataset):\n",
    "    def __init__(self, root, fold, magnification, train, transform=None, pre_transform=None, pre_filter=None):\n",
    "        self.fold = fold\n",
    "        self.fold_temp = fold\n",
    "        if fold == 'fold4':\n",
    "            self.fold_temp = 'fold1'\n",
    "        elif fold == 'fold5':\n",
    "            self.fold_temp = 'fold2'\n",
    "        self.magnification = magnification\n",
    "        self.train = train\n",
    "        super().__init__(root + self.fold_temp + '/', transform, pre_transform, pre_filter)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return '../../../../feature_extractor_6class/VPC_embeddings/{}'.format(self.fold_temp)\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        graphs = [f for f in os.listdir(self.root + '/processed') \n",
    "                    if f.split('_')[-1] == f'{self.magnification}.pt']\n",
    "        if self.fold in ['fold1', 'fold2', 'fold3']:\n",
    "            if self.train:\n",
    "                return graphs[:len(graphs)*4//5]\n",
    "            else:\n",
    "                return graphs[len(graphs)*4//5:]\n",
    "        if self.train:\n",
    "            return graphs[len(graphs)//5:]\n",
    "        else:\n",
    "            return graphs[:len(graphs)//5]\n",
    "\n",
    "    def download(self):\n",
    "        # Download to `self.raw_dir`.\n",
    "        assert False, 'went to download'\n",
    "\n",
    "    def process(self):\n",
    "        assert False, 'went to process'\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.processed_file_names)\n",
    "\n",
    "    def get(self, idx):\n",
    "        data = torch.load(os.path.join(self.processed_dir, self.processed_file_names[idx]))\n",
    "        return data, self.processed_file_names[idx][:16]\n",
    "    \n",
    "\n",
    "## Zurich dataset\n",
    "class ZurichDataset(Dataset):\n",
    "    def __init__(self, root, slides, fold, magnification, transform=None, pre_transform=None, pre_filter=None):\n",
    "        self.fold = fold\n",
    "        self.magnification = magnification\n",
    "        self.slides = slides\n",
    "        super().__init__(root + fold + '/', transform, pre_transform, pre_filter)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return '../../../../feature_extractor_6class/VPC_embeddings/{}'.format(self.fold)\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "#         return ['not_implemented']\n",
    "        return [f for f in os.listdir(self.root + '/processed') \n",
    "                if f.split('_')[-1] == f'{self.magnification}.pt' and f.split('_')[0] in self.slides]\n",
    "\n",
    "    def download(self):\n",
    "        # Download to `self.raw_dir`.\n",
    "        assert False, 'went to download'\n",
    "\n",
    "    def process(self):\n",
    "        assert False, 'went to process'\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.processed_file_names)\n",
    "\n",
    "    def get(self, idx):\n",
    "        data = torch.load(os.path.join(self.processed_dir, self.processed_file_names[idx]))\n",
    "        return data, self.processed_file_names[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9a7091",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if train_on == 'Karolinska':\n",
    "    dataset_train = VPCDataset(data_path, fold, magnification, True)\n",
    "    dataset_val = VPCDataset(data_path, fold, magnification, False)\n",
    "\n",
    "    loader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "    loader_val = DataLoader(dataset_val, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c253400c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setting training weights\n",
    "weights = torch.zeros((6,), dtype=torch.int16)\n",
    "for data, core_name in loader_train:\n",
    "    if magnification == 'heterogeneous':\n",
    "        for c in data['0'].y:\n",
    "            weights[c] += 1\n",
    "    else:\n",
    "        for c in data.y:\n",
    "            weights[c] += 1\n",
    "\n",
    "weights = weights.detach()\n",
    "weights = 1 / (weights)# + 1e-8) # avoid division by 0\n",
    "weights /= torch.sum(weights)\n",
    "print(weights)\n",
    "\n",
    "### setting validation weights\n",
    "weights_val = torch.zeros((6,), dtype=torch.int16)\n",
    "for data, core_name in loader_val:\n",
    "    if magnification == 'heterogeneous':\n",
    "        for c in data['0'].y:\n",
    "            weights_val[c] += 1\n",
    "    else:\n",
    "        for c in data.y:\n",
    "            weights_val[c] += 1\n",
    "\n",
    "weights_val = weights_val.detach()\n",
    "weights_val = 1 / (weights_val)# + 1e-8) # avoid division by 0\n",
    "weights_val /= torch.sum(weights_val)\n",
    "print(weights_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925e970c",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2029fe06-21df-470f-b0b0-10e2be37fbd3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DeepMIL(nn.Module):\n",
    "    def __init__(self, feature_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.L = feature_size\n",
    "        self.D = 128\n",
    "        self.K = 1\n",
    "\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(self.L, self.D),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(self.D, self.K)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.L*self.K, self.D),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.D, num_classes)\n",
    "            # nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, H):\n",
    "        # x = x.squeeze(0)\n",
    "\n",
    "        # H = self.feature_extractor_part1(x)\n",
    "        # H = H.view(-1, 50 * 4 * 4)\n",
    "        # H = self.feature_extractor_part2(H)  # NxL\n",
    "\n",
    "        A = self.attention(H)  # NxK\n",
    "        A = torch.transpose(A, 1, 0)  # KxN\n",
    "        A = F.softmax(A, dim=1)  # softmax over N\n",
    "        \n",
    "        M = torch.mm(A, H)  # KxL\n",
    "\n",
    "        Y_prob = self.classifier(M)\n",
    "        # Y_hat = torch.ge(Y_prob, 0.5).float()\n",
    "\n",
    "        return A, Y_prob\n",
    "\n",
    "class MIL(nn.Module):\n",
    "    def __init__(self, feature_size, num_classes, MIL_type):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        if MIL_type == 'deep':\n",
    "            self.model = DeepMIL(feature_size, num_classes)\n",
    "        else:\n",
    "            assert False, \"MIL_type should be in ['deep', 'var'] set!\"\n",
    "            \n",
    "        \n",
    "    def forward(self, x, batch):\n",
    "        # x, batch = data.x.float(), data.batch\n",
    "        batch_size = batch[-1].detach() + 1\n",
    "        embed_dim = x.shape[-1]\n",
    "        output = torch.zeros((batch_size, num_classes)).to(x.get_device())\n",
    "        for b in range(batch_size):\n",
    "            # x_batch = x[batch == b].unsqueeze(0)\n",
    "            x_batch = x[batch == b]\n",
    "            _, output[b] = self.model(x_batch) # in for loop since the dimensions does not match\n",
    "            \n",
    "        return output\n",
    "    \n",
    "    def prediction(self, data):\n",
    "        return torch.argmax(self.forward(data), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f1ee1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Rel_GNN(torch.nn.Module):\n",
    "    def __init__(self, feature_size, num_classes):\n",
    "        super().__init__()\n",
    "        embedding_size = 16\n",
    "        # dim = 32\n",
    "        # num_relations = 5\n",
    "        \n",
    "        # gnn layers # Edge_types mapping: 10_10: 0, 20_20: 1, 40_40: 2, 10_20: 3, 20_40: 3\n",
    "        self.neigh1 = RGCNConv(feature_size, feature_size, 3, is_sorted=True)\n",
    "        self.neigh2 = RGCNConv(feature_size, feature_size, 3, is_sorted=True)\n",
    "        self.mag = RGCNConv(feature_size, feature_size, 6, is_sorted=True)\n",
    "        self.neigh3 = RGCNConv(feature_size, embedding_size*8, 3, is_sorted=True)\n",
    "        self.neigh4 = RGCNConv(embedding_size*8, embedding_size*2, 3, is_sorted=True)\n",
    "        \n",
    "        # normalization\n",
    "        # self.norm_neigh1 = LayerNorm(feature_size)\n",
    "        # self.norm_neigh2 = LayerNorm(feature_size)\n",
    "        # self.norm_mag = LayerNorm(feature_size)\n",
    "        self.norm_neigh3 = LayerNorm(feature_size)\n",
    "        self.norm_neigh4 = LayerNorm(embedding_size*8)\n",
    "\n",
    "        # pooling\n",
    "        self.pool = MIL(embedding_size*2*3, num_classes, 'deep')\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x, batch = data['0'].x.float(), data['0'].batch\n",
    "        # edge_index, edge_type = get_edge_index_type(data)\n",
    "        \n",
    "        neigh_edge_index = torch.cat((data.edge_index_dict[('0','0','0')], data.edge_index_dict[('0','1','0')], data.edge_index_dict[('0','2','0')]), dim=1)\n",
    "        neigh_edge_type = torch.cat((torch.zeros(data.edge_index_dict[('0','0','0')].shape[1], dtype=torch.long), \n",
    "                                     torch.ones(data.edge_index_dict[('0','1','0')].shape[1], dtype=torch.long),\n",
    "                                    torch.ones(data.edge_index_dict[('0','2','0')].shape[1], dtype=torch.long)*2))\n",
    "        \n",
    "        ### neighbor block\n",
    "        # x = self.norm_neigh1(x, batch)\n",
    "        x = self.neigh1(x, neigh_edge_index, neigh_edge_type)\n",
    "        # x = self.norm_neigh2(x, batch)\n",
    "        # x = F.relu(x)\n",
    "        x = self.neigh2(x, neigh_edge_index, neigh_edge_type)\n",
    "        # x = self.norm_mag(x, batch)\n",
    "        # x = F.relu(x)\n",
    "        \n",
    "        ### magnification block # 10:0, 20:1, 40:2\n",
    "        n = x.shape[0] // 3\n",
    "        mag_edge_index = torch.empty((2,0), dtype=torch.long).cuda()\n",
    "        mag_edge_type = torch.zeros((n*6), dtype=torch.long).cuda()\n",
    "        for i in range(1,6):\n",
    "            mag_edge_type[i*n:(i+1)*n] = i\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                if i == j: continue\n",
    "                mag_edge_index = torch.cat((mag_edge_index, torch.tensor([range(i,n*3,3), range(j,n*3,3)]).cuda()), dim=1)\n",
    "        \n",
    "        \n",
    "        x = self.mag(x, mag_edge_index, mag_edge_type)\n",
    "        x = self.norm_neigh3(x, batch)\n",
    "        x = F.relu(x)\n",
    "        ### neighbor block\n",
    "        x = self.neigh3(x, neigh_edge_index, neigh_edge_type)\n",
    "        x = self.norm_neigh4(x, batch)\n",
    "        x = F.relu(x)\n",
    "        x = self.neigh4(x, neigh_edge_index, neigh_edge_type)\n",
    "        # x = F.relu(x)\n",
    "        \n",
    "        batch = batch[range(0, x.shape[0], 3)]\n",
    "        x = torch.cat((x[range(0, x.shape[0], 3)], x[range(1, x.shape[0], 3)], x[range(2, x.shape[0], 3)]), dim=1)\n",
    "        \n",
    "        ### aggregation\n",
    "        x = self.pool(x, batch=batch)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def prediction(self, data):\n",
    "        return torch.argmax(self.forward(data), dim=1)\n",
    "    \n",
    "class simple_GNN(torch.nn.Module):\n",
    "    def __init__(self, feature_size, num_classes):\n",
    "        super().__init__()\n",
    "        embedding_size = 16\n",
    "        # dim = 32\n",
    "        # num_relations = 5\n",
    "        \n",
    "        self.neigh1 = GCNConv(feature_size, feature_size, is_sorted=True)\n",
    "        self.neigh2 = GCNConv(feature_size, feature_size, is_sorted=True)\n",
    "        self.mag = GCNConv(feature_size, feature_size, is_sorted=True)\n",
    "        self.neigh3 = GCNConv(feature_size, embedding_size*8, is_sorted=True)\n",
    "        self.neigh4 = GCNConv(embedding_size*8, embedding_size*2, is_sorted=True)\n",
    "        \n",
    "        # normalization\n",
    "        # self.norm_neigh1 = LayerNorm(feature_size)\n",
    "        # self.norm_neigh2 = LayerNorm(feature_size)\n",
    "        # self.norm_mag = LayerNorm(feature_size)\n",
    "        self.norm_neigh3 = LayerNorm(feature_size)\n",
    "        self.norm_neigh4 = LayerNorm(embedding_size*8)\n",
    "\n",
    "        # pooling\n",
    "        self.pool = MIL(embedding_size*2*3, num_classes, 'deep')\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x, batch = data['0'].x.float(), data['0'].batch\n",
    "        # edge_index, edge_type = get_edge_index_type(data)\n",
    "        \n",
    "        neigh_edge_index = torch.cat((data.edge_index_dict[('0','0','0')], data.edge_index_dict[('0','1','0')], data.edge_index_dict[('0','2','0')]), dim=1)\n",
    "        neigh_edge_type = torch.cat((torch.zeros(data.edge_index_dict[('0','0','0')].shape[1]), torch.ones(data.edge_index_dict[('0','1','0')].shape[1]),\n",
    "                                    torch.ones(data.edge_index_dict[('0','2','0')].shape[1])*2))\n",
    "        \n",
    "        ### neighbor block\n",
    "        # x = self.norm_neigh1(x, batch)\n",
    "        x = self.neigh1(x, neigh_edge_index)\n",
    "        # x = self.norm_neigh2(x, batch)\n",
    "        # x = F.relu(x)\n",
    "        x = self.neigh2(x, neigh_edge_index)\n",
    "        # x = self.norm_mag(x, batch)\n",
    "        # x = F.relu(x)\n",
    "        \n",
    "        ### magnification block # 10:0, 20:1, 40:2\n",
    "        n = x.shape[0] // 3\n",
    "        mag_edge_index = torch.empty((2,0), dtype=torch.long).cuda()\n",
    "        mag_edge_type = torch.zeros((n*6), dtype=torch.long).cuda()\n",
    "        for i in range(1,6):\n",
    "            mag_edge_type[i*n:(i+1)*n] = i\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                if i == j: continue\n",
    "                mag_edge_index = torch.cat((mag_edge_index, torch.tensor([range(i,n*3,3), range(j,n*3,3)]).cuda()), dim=1)\n",
    "        \n",
    "        \n",
    "        x = self.mag(x, mag_edge_index)\n",
    "        x = self.norm_neigh3(x, batch)\n",
    "        x = F.relu(x)\n",
    "        ### neighbor block\n",
    "        x = self.neigh3(x, neigh_edge_index)\n",
    "        x = self.norm_neigh4(x, batch)\n",
    "        x = F.relu(x)\n",
    "        x = self.neigh4(x, neigh_edge_index)\n",
    "        # x = F.relu(x)\n",
    "        \n",
    "        batch = batch[range(0, x.shape[0], 3)]\n",
    "        x = torch.cat((x[range(0, x.shape[0], 3)], x[range(1, x.shape[0], 3)], x[range(2, x.shape[0], 3)]), dim=1)\n",
    "        \n",
    "        ### aggregation\n",
    "        x = self.pool(x, batch=batch)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def prediction(self, data):\n",
    "        return torch.argmax(self.forward(data), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b38b25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "if magnification == 'heterogeneous':\n",
    "    model = Rel_GNN(dataset_train[0][0]['0'].num_node_features, num_classes).to(device)\n",
    "else:\n",
    "    model = simple_GNN(dataset_train.num_node_features, num_classes).to(device)\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(params)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ca048b",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd692c06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "# prepare plotting\n",
    "fig = plt.figure(figsize=(20, 5), dpi= 80, facecolor='w', edgecolor='k')\n",
    "axes = fig.subplots(1,3)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor = 0.3, patience=10, verbose=True)\n",
    "\n",
    "sm = torch.nn.Softmax(dim=1)\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "val_accs = []\n",
    "val_auc = []\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for i, (data, core_name) in enumerate(loader_train):\n",
    "        if magnification == 'heterogeneous':\n",
    "            y = data['0'].y\n",
    "        else:\n",
    "            y = data.y\n",
    "        optimizer.zero_grad()\n",
    "        data.to(device)\n",
    "        pred = model(data)\n",
    "#         print(pred)\n",
    "        loss = F.cross_entropy(pred.to('cpu'), F.one_hot(y, num_classes=num_classes).double(), weight = weights)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "    \n",
    "    model.eval()\n",
    "    pred_val = np.zeros(len(dataset_val))\n",
    "    pred_val_loss = torch.zeros((len(dataset_val), num_classes))\n",
    "    label = torch.zeros(len(dataset_val), dtype=torch.long).detach()\n",
    "    for i, (data, core_name) in enumerate(loader_val):\n",
    "        index = i*batch_size\n",
    "        if magnification == 'heterogeneous':\n",
    "            y = data['0'].y\n",
    "        else:\n",
    "            y = data.y\n",
    "        label[index:index + y.shape[0]] = y\n",
    "        data.to(device)\n",
    "        pred = model(data)\n",
    "        pred_val[index:index + y.shape[0]] = torch.argmax(pred, dim=1).cpu().detach().numpy()\n",
    "        \n",
    "        pred_val_loss[index:index + y.shape[0], :] = pred.cpu().detach()\n",
    "        \n",
    "    loss = F.cross_entropy(pred_val_loss, F.one_hot(label, num_classes=num_classes).double(), weight = weights_val)\n",
    "    auc = roc_auc_score(label, sm(pred_val_loss), average ='macro', multi_class='ovr')\n",
    "    label = label.numpy()\n",
    "    val_acc = np.mean(label == pred_val)\n",
    "    val_accs.append(val_acc)\n",
    "    val_losses.append(loss.item())\n",
    "    val_auc.append(auc)\n",
    "    \n",
    "    for ax in axes:\n",
    "        ax.cla()\n",
    "    # plot the training loss on a log plot\n",
    "    axes[0].plot(losses, label='loss')\n",
    "    axes[0].set_yscale('log')\n",
    "    axes[0].set_title('Training loss')\n",
    "    axes[0].set_xlabel('number of gradient iterations')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    # plot the validation loss on a log plot\n",
    "    axes[1].plot(val_losses, label='loss')\n",
    "    axes[1].set_yscale('log')\n",
    "    axes[1].set_title('Validation loss')\n",
    "    axes[1].set_xlabel('number of epochs')\n",
    "    axes[1].legend()\n",
    "    \n",
    "    # plot the validation loss on a log plot\n",
    "    axes[2].plot(val_accs, label='val_acc')\n",
    "    axes[2].plot(val_auc, label='val_auc')\n",
    "#     axes[1].set_yscale('log')\n",
    "    axes[2].set_title('Validation Accuracy')\n",
    "    axes[2].set_xlabel('number of epochs')\n",
    "    axes[2].legend()\n",
    "    \n",
    "    # clear output window and diplay updated figure\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    print(f'Epoch{epoch + 1} of {num_epochs} ({100*(epoch + 1)/num_epochs})%, val_acc = {val_acc}, val_auc = {auc}')\n",
    "    \n",
    "    ## saving the model\n",
    "    save_model(auc, epoch, model, optimizer)\n",
    "    \n",
    "    scheduler.step(loss)\n",
    "    \n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d680960-792f-46d9-a931-728575659ecf",
   "metadata": {},
   "source": [
    "# Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9267547a-129f-425f-a0c4-e47ec5e0ff53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class testDataset(Dataset):\n",
    "    def __init__(self, root, fold, magnification, transform=None, pre_transform=None, pre_filter=None):\n",
    "        self.fold = fold\n",
    "        self.fold_temp = fold\n",
    "        if fold == 'fold4':\n",
    "            self.fold_temp = 'fold1'\n",
    "        elif fold == 'fold5':\n",
    "            self.fold_temp = 'fold2'\n",
    "        self.magnification = magnification\n",
    "        super().__init__(root + self.fold_temp + '/', transform, pre_transform, pre_filter)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return '../../../../feature_extractor_6class/VPC_embeddings/{}'.format(self.fold_temp)\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [f for f in os.listdir(self.root + '/processed') \n",
    "                    if f.split('_')[-1] == f'{self.magnification}.pt']\n",
    "\n",
    "    def download(self):\n",
    "        # Download to `self.raw_dir`.\n",
    "        assert False, 'went to download'\n",
    "\n",
    "    def process(self):\n",
    "        assert False, 'went to process'\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.processed_file_names)\n",
    "\n",
    "    def get(self, idx):\n",
    "        data = torch.load(os.path.join(self.processed_dir, self.processed_file_names[idx]))\n",
    "        return data, self.processed_file_names[idx][:16]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f0a29c",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fc9e43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if train_on == 'Karolinska':\n",
    "    data_path = 'Radboud_data/'\n",
    "    dataset_test = testDataset(data_path, fold, magnification)\n",
    "    loader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n",
    "else:\n",
    "    data_path = 'Zurich_data/'\n",
    "    dataset_test = ZurichDataset(data_path, test_slides_zurich, fold, magnification)\n",
    "    loader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "sm = torch.nn.Softmax(dim=1)\n",
    "\n",
    "checkpoint = torch.load(model_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "pred_file = f'results/{fold}/ms_rgcn_pred.npy'\n",
    "label_file = f'results/{fold}/ms_rgcn_label.npy'\n",
    "\n",
    "print(checkpoint['val_acc'])\n",
    "print(model_path)\n",
    "print(pred_file)\n",
    "print(label_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c2759d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "test_iter = iter(loader_test)\n",
    "model.eval()\n",
    "pred_test = np.zeros((len(dataset_test), num_classes))\n",
    "label = np.zeros(len(dataset_test))\n",
    "for i, (data, core_name) in enumerate(loader_test):\n",
    "    index = i*batch_size\n",
    "    if magnification == 'heterogeneous':\n",
    "        y = data['0'].y\n",
    "    else:\n",
    "        y = data.y\n",
    "    label[index:index + y.shape[0]] = y\n",
    "    data.to(device)\n",
    "    pred = sm(model(data).cpu())\n",
    "    pred_test[index:index + y.shape[0], :] = pred.detach().numpy()\n",
    "toc = time.time()\n",
    "print(f'duration: {(toc - tic)*1000 / len(dataset_test):.2f} ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17c0d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pred_file, 'wb') as f:\n",
    "    np.save(f, pred_test)\n",
    "with open(label_file, 'wb') as f:\n",
    "    np.save(f, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715fa88e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(roc_auc_score(label,pred_test,average ='macro', multi_class='ovr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43ad703",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "score = quadratic_weighted_kappa(np.argmax(pred_test, axis=1), label)\n",
    "\n",
    "print(f\"kappa panda: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4794dd4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f'Balanced accuracy: {balanced_accuracy_score(label, np.argmax(pred_test, axis=1))}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
